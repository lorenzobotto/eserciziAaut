{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEKy3XmT7H-U"
      },
      "source": [
        "# # Introduzione ai classificatori\n",
        "\n",
        "Nel seguente programma introduciamo i passi base della classificazione degli esempi di un dataset rappresentato come una matrice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btrnWCpJ7H-W"
      },
      "source": [
        "Importiamo il package per l'apprendimento degli alberi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QFXKb7yA7H-X",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from sklearn import tree "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Sx9T_yz7H-f"
      },
      "source": [
        "Definiamo la matrice con i dati (un esempio per riga)\n",
        "e il vettore con il corrispondente valore della variabile target "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HDFiRDXq7H-g"
      },
      "outputs": [],
      "source": [
        "# 6 esempi, 3 features per ogni esempio\n",
        "# X sono le features\n",
        "X = [[0, 0, 0], [1, 1, 1], [0, 1, 0], [0, 0, 1], [1, 1, 0], [1, 0, 1]]\n",
        "# Y sono le etichette target\n",
        "Y = [1, 0, 0, 0, 1, 1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLgMBwpZ7H-n"
      },
      "source": [
        "Dichiariamo il modello di classificazione che vogliamo usare e poi lo adattiamo (fit) ai dati"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbHJM2ur7H-o"
      },
      "outputs": [],
      "source": [
        "clf = tree.DecisionTreeClassifier()\n",
        "# Fittiamo il modello sui dati\n",
        "clf = clf.fit(X, Y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUtyP-xO7H-t"
      },
      "source": [
        "Prediciamo il valore della variabile target (e lo visualizziamo) per i dati passati, e usiamo il modello 'fittato' in clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTo8XvPr7H-v",
        "outputId": "f2c67b3c-9ce6-4dfb-e69f-ce9120823c53"
      },
      "outputs": [],
      "source": [
        "# Diamo un nuovo esempio che non ha mai visto e vediamo quale classe predice\n",
        "print(clf.predict([[0, 1, 1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sw1x57GnM72b"
      },
      "source": [
        "Visualizziamo l'albero appreso. \n",
        "\n",
        "---\n",
        "Prima importiamo la libreria per la visualizzazione dei grafi (graphviz).\n",
        "Poi esportiamo il classificatore in clf in una variabile che contiene la sua descrizione nel linguaggio dot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qP9sNQ2t7H-5",
        "outputId": "7b57e3de-e2a2-4b38-f699-c6c2106e1bf0"
      },
      "outputs": [],
      "source": [
        "import graphviz \n",
        "dot_data = tree.export_graphviz(clf, out_file=None)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oCMYXsO7H--"
      },
      "source": [
        "Nel seguito usiamo il dataset Iris (dall'archivio dell'Università della California di Irvine (UCI) di Machine Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QICMJ0rv7H-_"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzZnLA4N7H_D"
      },
      "source": [
        "# Dichiariamo il tipo del modello predittivo e i parametri dell'apprendimento dell'algoritmo di induzione del modello ad albero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ul-cA4Hv7H_E"
      },
      "outputs": [],
      "source": [
        "# Usa come criterio di split entropy\n",
        "# Inizializza in maniera casuale il random state pari a 300 (per fare delle scelte di suddivisione di training e test set)\n",
        "# min_samples minimo di numero dei campioni per foglia, se il valore scende sotto il minimo non faccio la foglia\n",
        "# per evitare l'overfitting.\n",
        "# Diamo i pesi da associare alle classi, diamo dei pesi unitari. Alla classe 0, diamo il peso 1. Alla classe 1, diamo il \n",
        "# peso 1 e così via.\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iqH8H1UD7H_H"
      },
      "source": [
        "# Dividiamo il dataset in training e test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSKsWOoz7H_I"
      },
      "outputs": [],
      "source": [
        "# Generiamo una permutazione casuale degli indici degli esempiche verranno usati per il training e il test set\n",
        "import numpy as np\n",
        "np.random.seed(0)\n",
        "# Prendiamo un vettore pari alla lunghezza del dataset (lunghezza iris è 150) ordinandoli in modo casuale\n",
        "indices = np.random.permutation(len(iris.data))\n",
        "\n",
        "# Decidiamo di tenere gli ultimi 10 indici per il test set, i rimanenti per il training set\n",
        "indices_training=indices[:-10]\n",
        "indices_test=indices[-10:]\n",
        "\n",
        "# Componiamo le matrici dividendo training e test set con le relative classi target\n",
        "iris_X_train = iris.data[indices_training] # teniamo per il training tutti gli elementi della  matrice tranne gli ultimi 10 \n",
        "iris_y_train = iris.target[indices_training]\n",
        "iris_X_test  = iris.data[indices_test] # teniamo da parte gli ultimi 10 elementi per il test set\n",
        "iris_y_test  = iris.target[indices_test]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNbXUYI07H_K"
      },
      "source": [
        "# Fittiamo il modello sul training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1A3MqXZs7H_L"
      },
      "outputs": [],
      "source": [
        "# fit the model to the training data\n",
        "# Qua avviene il vero e proprio apprendimento\n",
        "clf = clf.fit(iris_X_train, iris_y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPdjlWZB7H_P"
      },
      "source": [
        "# Otteniamo le predizioni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qMP6rS-97H_P",
        "outputId": "e0f9707c-5465-4128-9eb2-0c43f4a3f75b"
      },
      "outputs": [],
      "source": [
        "# Chiediamo di predire le classi del test set\n",
        "# applichiamo il modello fittato in \"clf\" al test set \n",
        "predicted_y_test = clf.predict(iris_X_test)\n",
        "\n",
        "# visualizziamo le predizioni (gli indici delle classi associati ai nomi delle classi in target_names)\n",
        "print(\"Predictions:\")\n",
        "print(predicted_y_test)\n",
        "print(\"True classes:\")\n",
        "print(iris_y_test) \n",
        "print(iris.target_names)\n",
        "\n",
        "# Vediamo che c'è solo un errore sul secondo esempio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TZyuYLx7H_T"
      },
      "source": [
        "Visualizza l'indice delle instanze di test e le corrispondenti predizioni"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRz0f9NK7H_T",
        "outputId": "4a04bd5b-ee05-491d-8cac-adcfd17fb81f"
      },
      "outputs": [],
      "source": [
        "# print the corresponding instances indexes and class names \n",
        "for i in range(len(iris_y_test)): \n",
        "    print(\"Instance # \"+str(indices_test[i])+\": \")\n",
        "    print(\"Predicted: \"+iris.target_names[predicted_y_test[i]]+\"\\t True: \"+iris.target_names[iris_y_test[i]]+\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yj3hYAqQ7H_W"
      },
      "source": [
        "# Vediamo alcuni esempi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HGKB-S6b7H_X",
        "outputId": "819c7ba9-56a8-41dc-f61e-d59a1a893ffe"
      },
      "outputs": [],
      "source": [
        "for i in range(len(iris_y_test)): \n",
        "    print(\"Instance # \"+str(indices_test[i])+\": \")\n",
        "    s=\"\"\n",
        "    for j in range(len(iris.feature_names)):\n",
        "        s=s+iris.feature_names[j]+\"=\"+str(iris_X_test[i][j])\n",
        "        if (j<len(iris.feature_names)-1): s=s+\", \"\n",
        "    print(s)\n",
        "    print(\"Predicted: \"+iris.target_names[predicted_y_test[i]]+\"\\t True: \"+iris.target_names[iris_y_test[i]]+\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9zos0wm7H_Z"
      },
      "source": [
        "# Otteniamo i risultati delle predizioni (model performance results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HBNKQQqa7H_a",
        "outputId": "09c73bd7-5f55-4409-8958-0705aa4b73be"
      },
      "outputs": [],
      "source": [
        "# print some metrics results\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "acc_score = accuracy_score(iris_y_test, predicted_y_test)\n",
        "print(\"Accuracy score: \"+ str(acc_score))\n",
        "\n",
        "# Recall capacità di richiamare correttamente gli esempi\n",
        "# f1 score è la media armonica e si moltiplica per due perchè sia recall che precision hanno lo stesso peso\n",
        "f1=f1_score(iris_y_test, predicted_y_test, average='macro')\n",
        "print(\"F1 score: \"+str(f1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNO0xcGq7H_c"
      },
      "source": [
        "# Usiamo la Cross Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wmt414Lm7H_c",
        "outputId": "da09947d-d490-4717-cd7c-c2c544a0d261"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
        "iris = load_iris()\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:1})\n",
        "clf = clf.fit(iris.data, iris.target)\n",
        "\n",
        "# Gli passiamo il calssificatore che è stato fittato, la matrice dei dati, la matrice dei target\n",
        "# cv le soglie di taglio, 5 cluster vector, ogni cluster 30 esempi perchè abbiamo 150 esempi.\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5) # score will be the accuracy\n",
        "print(scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-rd5Dq77H_e",
        "outputId": "0c1f75ee-948a-4184-a9f1-7c10a7747aeb"
      },
      "outputs": [],
      "source": [
        "# computes F1- score\n",
        "f1_scores = cross_val_score(clf, iris.data, iris.target, cv=5, scoring='f1_macro')\n",
        "print(f1_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcnegz_A7H_h"
      },
      "source": [
        "# Mostriamo l'albero risultante "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrA-f0e27H_i"
      },
      "source": [
        "## 1. Visualizza la figura dell'albero in un file PDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPYEWkcH7H_i",
        "outputId": "28d4261a-7ad1-47a1-ab5d-a0583bfc014d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "import graphviz \n",
        "dot_data = tree.export_graphviz(clf, out_file=None) \n",
        "graph = graphviz.Source(dot_data) \n",
        "graph.render(\"my_iris_predictions\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM67N3vc7H_k"
      },
      "source": [
        "## 2. Genera la figura"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "prgjDOka7H_l",
        "outputId": "2263ea70-f260-4933-80f3-63bc23d00ace"
      },
      "outputs": [],
      "source": [
        "print(list(iris.feature_names))\n",
        "print(list(iris.target_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pr32sBno7H_n",
        "outputId": "6f741234-c217-448b-b711-ed46e541e862"
      },
      "outputs": [],
      "source": [
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                         feature_names=iris.feature_names, \n",
        "                         class_names=iris.target_names, \n",
        "                         filled=True, rounded=True,  \n",
        "                         special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Le celle seguenti le creerete voi: ecco cosa dovete fare\n",
        "Modificare questo Jupyter notebook sui decision trees sul dataset Iris e svolgete i seguenti compiti:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zzHbGJsTOoQU"
      },
      "source": [
        "1. applicate un sovracampionamento (artificial inflation) ad una classe nel training set con un determinato fattore: 10 (si pesi di più una delle classi tra virginica o versicolor che sono più difficili da discriminare). Si apprenda l'albero di decisione in queste condizioni.\n",
        "    - 1b. modifcare i pesi della stessa classe (si metta a 10 il peso per l'errata predizione ad esempio di Virginica in Versicolor o viceversa) e si apprenda  l'albero in queste condizioni. Dovreste ottenere risultati simili a quelli del punto 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
        "iris = load_iris()\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:1,2:10})\n",
        "clf = clf.fit(iris.data, iris.target)\n",
        "\n",
        "# Gli passiamo il calssificatore che è stato fittato, la matrice dei dati, la matrice dei target\n",
        "# cv le soglie di taglio, 5 cluster vector, ogni cluster 30 esempi perchè abbiamo 150 esempi.\n",
        "# cv quindi sono 5 fold.\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5) # score will be the accuracy\n",
        "print(scores)\n",
        "\n",
        "# TODO Duplicare a mano gli esempi "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
        "iris = load_iris()\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,class_weight={0:1,1:10,2:1})\n",
        "clf = clf.fit(iris.data, iris.target)\n",
        "\n",
        "# Gli passiamo il calssificatore che è stato fittato, la matrice dei dati, la matrice dei target\n",
        "# cv le soglie di taglio, 5 cluster vector, ogni cluster 30 esempi perchè abbiamo 150 esempi.\n",
        "# cv quindi sono 5 fold.\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5) # score will be the accuracy\n",
        "print(scores)\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                         feature_names=iris.feature_names, \n",
        "                         class_names=iris.target_names, \n",
        "                         filled=True, rounded=True,  \n",
        "                         special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "2. si apprendano gli alberi cercando di evitare l'overfitting (migliorando l'errore sul test set) facendo 'tuning' degli iper-parametri: il minimo numero dei campioni per foglia, la massima profondità dell'albero, i parametri di minomo decremento dell'impurezza, massimo numero dei nodi foglia, ecc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
        "iris = load_iris()\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,max_leaf_nodes=3,min_impurity_decrease=0.2,max_depth=2,class_weight={0:1,1:10,2:1})\n",
        "clf = clf.fit(iris.data, iris.target)\n",
        "\n",
        "# Gli passiamo il calssificatore che è stato fittato, la matrice dei dati, la matrice dei target\n",
        "# cv le soglie di taglio, 5 cluster vector, ogni cluster 30 esempi perchè abbiamo 150 esempi.\n",
        "# cv quindi sono 5 fold.\n",
        "scores = cross_val_score(clf, iris.data, iris.target, cv=5) # score will be the accuracy\n",
        "print(scores)\n",
        "dot_data = tree.export_graphviz(clf, out_file=None, \n",
        "                         feature_names=iris.feature_names, \n",
        "                         class_names=iris.target_names, \n",
        "                         filled=True, rounded=True,  \n",
        "                         special_characters=True)  \n",
        "graph = graphviz.Source(dot_data)  \n",
        "graph\n",
        "\n",
        "# In questo modo si vede che in confronto a prima classifica molto meglio perchè versicolo non ha un sacco di nodi foglia,\n",
        "# ma solo uno. Non ha senso splittare un nodo versicolor in altri nodi che comunque hanno target versicolor."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "3. si costruisca la matrice di confusione dell'albero creato  sul test set e la si visualizzi. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x24c48a01180>"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(0)\n",
        "# Prendiamo un vettore pari alla lunghezza del dataset (lunghezza iris è 150) ordinandoli in modo casuale\n",
        "indices = np.random.permutation(len(iris.data))\n",
        "\n",
        "# Decidiamo di tenere gli ultimi 10 indici per il test set, i rimanenti per il training set\n",
        "indices_training=indices[:-10]\n",
        "indices_test=indices[-10:]\n",
        "\n",
        "# Componiamo le matrici dividendo training e test set con le relative classi target\n",
        "iris_X_train = iris.data[indices_training] # teniamo per il training tutti gli elementi della  matrice tranne gli ultimi 10 \n",
        "iris_y_train = iris.target[indices_training]\n",
        "iris_X_test  = iris.data[indices_test] # teniamo da parte gli ultimi 10 elementi per il test set\n",
        "iris_y_test  = iris.target[indices_test]\n",
        "\n",
        "# Fittiamo il modello\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,max_leaf_nodes=3,min_impurity_decrease=0.2,max_depth=2,class_weight={0:1,1:10,2:1})\n",
        "clf = clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "# Predizioni sul test set\n",
        "predicted_y_test = clf.predict(iris_X_test)\n",
        "\n",
        "mc = confusion_matrix(iris_y_test, predicted_y_test)\n",
        "mc\n",
        "\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=mc,\n",
        "                               display_labels=clf.classes_)\n",
        "\n",
        "disp.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90GvIMjgeUue"
      },
      "source": [
        "\n",
        "4. si costruiscano le curve ROC (o curve nello spazio di coverage) e le si mostri per ciascun modello ad albero creato su un problema binario (con 1 sola classe positiva): per ciascun modello dovete costruire tre curve, una per ciascuna classe, considerata a turno la classe positiva. (scikit learn roc curve)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "iris = load_iris()\n",
        "print(iris.target)\n",
        "newTarget = iris.target\n",
        "newTarget[newTarget == 2] = 1\n",
        "\n",
        "iris.target = newTarget\n",
        "print(iris.target)\n",
        "iris.target_names = np.array(['setosa', 'not setosa'])\n",
        "\n",
        "np.random.seed(0)\n",
        "# Prendiamo un vettore pari alla lunghezza del dataset (lunghezza iris è 150) ordinandoli in modo casuale\n",
        "indices = np.random.permutation(len(iris.data))\n",
        "\n",
        "# Decidiamo di tenere gli ultimi 10 indici per il test set, i rimanenti per il training set\n",
        "indices_training=indices[:-10]\n",
        "indices_test=indices[-10:]\n",
        "\n",
        "# Componiamo le matrici dividendo training e test set con le relative classi target\n",
        "iris_X_train = iris.data[indices_training] # teniamo per il training tutti gli elementi della  matrice tranne gli ultimi 10 \n",
        "iris_y_train = iris.target[indices_training]\n",
        "iris_X_test  = iris.data[indices_test] # teniamo da parte gli ultimi 10 elementi per il test set\n",
        "iris_y_test  = iris.target[indices_test]\n",
        "\n",
        "# Fittiamo il modello\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,max_leaf_nodes=3,min_impurity_decrease=0.2,max_depth=2,class_weight={0:1,1:1})\n",
        "clf = clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "metrics.RocCurveDisplay.from_estimator(\n",
        "    clf, iris_X_test, iris_y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2]\n",
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index 1 is out of bounds for axis 0 with size 1",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [4], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m clf \u001b[39m=\u001b[39m tree\u001b[39m.\u001b[39mDecisionTreeClassifier(criterion\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mentropy\u001b[39m\u001b[39m\"\u001b[39m,random_state\u001b[39m=\u001b[39m\u001b[39m300\u001b[39m,min_samples_leaf\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,max_leaf_nodes\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m,min_impurity_decrease\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m,max_depth\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,class_weight\u001b[39m=\u001b[39m{\u001b[39m0\u001b[39m:\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m:\u001b[39m1\u001b[39m})\n\u001b[0;32m     33\u001b[0m clf \u001b[39m=\u001b[39m clf\u001b[39m.\u001b[39mfit(iris_X_train, iris_y_train)\n\u001b[1;32m---> 35\u001b[0m metrics\u001b[39m.\u001b[39;49mRocCurveDisplay\u001b[39m.\u001b[39;49mfrom_estimator(\n\u001b[0;32m     36\u001b[0m     clf, iris_X_test, iris_y_test)\n",
            "File \u001b[1;32mc:\\Users\\lores\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_plot\\roc_curve.py:231\u001b[0m, in \u001b[0;36mRocCurveDisplay.from_estimator\u001b[1;34m(cls, estimator, X, y, sample_weight, drop_intermediate, response_method, pos_label, name, ax, **kwargs)\u001b[0m\n\u001b[0;32m    227\u001b[0m check_matplotlib_support(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.from_estimator\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    229\u001b[0m name \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m name\n\u001b[1;32m--> 231\u001b[0m y_pred, pos_label \u001b[39m=\u001b[39m _get_response(\n\u001b[0;32m    232\u001b[0m     X,\n\u001b[0;32m    233\u001b[0m     estimator,\n\u001b[0;32m    234\u001b[0m     response_method\u001b[39m=\u001b[39;49mresponse_method,\n\u001b[0;32m    235\u001b[0m     pos_label\u001b[39m=\u001b[39;49mpos_label,\n\u001b[0;32m    236\u001b[0m )\n\u001b[0;32m    238\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mfrom_predictions(\n\u001b[0;32m    239\u001b[0m     y_true\u001b[39m=\u001b[39my,\n\u001b[0;32m    240\u001b[0m     y_pred\u001b[39m=\u001b[39my_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    246\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[0;32m    247\u001b[0m )\n",
            "File \u001b[1;32mc:\\Users\\lores\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_plot\\base.py:103\u001b[0m, in \u001b[0;36m_get_response\u001b[1;34m(X, estimator, response_method, pos_label)\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    102\u001b[0m     class_idx \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m--> 103\u001b[0m     pos_label \u001b[39m=\u001b[39m estimator\u001b[39m.\u001b[39;49mclasses_[class_idx]\n\u001b[0;32m    105\u001b[0m \u001b[39mif\u001b[39;00m y_pred\u001b[39m.\u001b[39mndim \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:  \u001b[39m# `predict_proba`\u001b[39;00m\n\u001b[0;32m    106\u001b[0m     y_pred_shape \u001b[39m=\u001b[39m y_pred\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n",
            "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for axis 0 with size 1"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import cross_val_score # will be used to separate training and test\n",
        "from sklearn import metrics\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "iris = load_iris()\n",
        "print(iris.target)\n",
        "newTarget = iris.target\n",
        "newTarget[newTarget == 1] = 0\n",
        "newTarget[newTarget == 0] = 1\n",
        "newTarget[newTarget == 2] = 1\n",
        "\n",
        "iris.target = newTarget\n",
        "print(iris.target)\n",
        "iris.target_names = np.array(['versicol', 'not versicol'])\n",
        "\n",
        "np.random.seed(0)\n",
        "# Prendiamo un vettore pari alla lunghezza del dataset (lunghezza iris è 150) ordinandoli in modo casuale\n",
        "indices = np.random.permutation(len(iris.data))\n",
        "\n",
        "# Decidiamo di tenere gli ultimi 10 indici per il test set, i rimanenti per il training set\n",
        "indices_training=indices[:-10]\n",
        "indices_test=indices[-10:]\n",
        "\n",
        "# Componiamo le matrici dividendo training e test set con le relative classi target\n",
        "iris_X_train = iris.data[indices_training] # teniamo per il training tutti gli elementi della  matrice tranne gli ultimi 10 \n",
        "iris_y_train = iris.target[indices_training]\n",
        "iris_X_test  = iris.data[indices_test] # teniamo da parte gli ultimi 10 elementi per il test set\n",
        "iris_y_test  = iris.target[indices_test]\n",
        "\n",
        "# Fittiamo il modello\n",
        "clf = tree.DecisionTreeClassifier(criterion=\"entropy\",random_state=300,min_samples_leaf=5,max_leaf_nodes=3,min_impurity_decrease=0.2,max_depth=2,class_weight={0:1,1:1})\n",
        "clf = clf.fit(iris_X_train, iris_y_train)\n",
        "\n",
        "metrics.RocCurveDisplay.from_estimator(\n",
        "    clf, iris_X_test, iris_y_test)"
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8"
    },
    "vscode": {
      "interpreter": {
        "hash": "7ce7c4955edd13c30a4146b31fdc101573b4ef2482afd4a7ebc3004a50006c28"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
